{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56c647e-6fba-4b78-b5b7-02f51b954da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Packages\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# import time\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Image wranglers\n",
    "import imageio\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "\n",
    "#Tocohpy functions \n",
    "import Optical_Components as comp\n",
    "import Optical_Propagators as prop\n",
    "import Helper_Functions as HF\n",
    "\n",
    "##GPU info for pytorch##\n",
    "gpu_no = 0\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda:\"+str(gpu_no) if use_cuda else \"cpu\")\n",
    "\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\"\"\" This Notebook is an example notebook for Optical NN learning with Tocohpy - Lionel Fiske  \"\"\"\n",
    "#Last update: 9/15/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bbe75a-70d3-438d-bcbc-c06e52824d2d",
   "metadata": {},
   "source": [
    "Tocohpy is a library of functions designed to prototype the design of optical systems which use learnable phase and absorption gratings. This notebook is a series of example problems which demonstrate how to use the tocohpy functions to build optical systems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23fd651",
   "metadata": {},
   "outputs": [],
   "source": [
    "## In this example a 4 f system will be modeled.\n",
    "##\n",
    "\n",
    "# units\n",
    "mm = 1e-3 #meters\n",
    "nm = 1e-9 #meters\n",
    "\n",
    "\n",
    "### Setting Problem Parameters ###\n",
    "\n",
    "#Masking the initial field \n",
    "s= (1024, 1024)      # size of simulation in pixels\n",
    "sim_size = 5*mm      # size of wavefront / simulation fox\n",
    "\n",
    "#coordinates \n",
    "x_c = torch.linspace(-sim_size/2,sim_size/2, s[0] )  #XCoordinates \n",
    "y_c = torch.linspace(-sim_size/2,sim_size/2, s[1] )  #YCoordinates \n",
    "[X,Y] = torch.meshgrid(x_c,y_c)    #Generate Coordinate Mesh\n",
    "R2= X**2 + Y**2                    #Radial coordinates\n",
    "dx = x_c[1] - x_c[0]               #grid spacing\n",
    "\n",
    "\n",
    "# Wavelength\n",
    "lamb  = 500.0* nm\n",
    "\n",
    "#Lens focal length\n",
    "focal_length = 25* mm \n",
    "\n",
    "#Define output target image\n",
    "\n",
    "#We load an image in and apply some padding \n",
    "s2=( int( s[0]/2)  ,int( s[1]/2 ) )\n",
    "field_in = torch.zeros(2 , 1, s[0], s[1], device = device, dtype = torch.cfloat)\n",
    "\n",
    "#Here I am loading in a few images and resampling them so they are the same size as my field\n",
    "resized_image = torch.tensor( np.array(Image.fromarray(imageio.imread('imageio:camera.png')).resize(s2)) )\n",
    "image_noise_padding = torch.nn.functional.pad(resized_image+ 0*torch.rand(s2), (int(1/4 * s[0]),int(1/4 * s[0]),int(1/4 * s[1]),int(1/4 * s[1])), mode='constant', value=0)   \n",
    "\n",
    "resized_image2 =torch.tensor( np.array(Image.fromarray(imageio.imread('imageio:astronaut.png')[:,:,0]).resize(s2)) )\n",
    "image_noise_padding2 = torch.nn.functional.pad(resized_image2+ 0*torch.rand(s2), (int(1/4 * s[0]),int(1/4 * s[0]),int(1/4 * s[1]),int(1/4 * s[1])), mode='constant', value=0)   \n",
    "\n",
    "\n",
    "## Tocohpy uses pytorch, so it can handle batch and channel dimensions.\n",
    "## load each image into a different batch number\n",
    "field_in[0,0,:,:] = ((1j)*image_noise_padding/255.0  ).to(device) \n",
    "field_in[1,0,:,:] = ((1j)*image_noise_padding2/255.0  ).to(device) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ca9376-f866-46da-afad-561e17c5f2bd",
   "metadata": {},
   "source": [
    "To create an optical path we define a dictionary of optical components and propagation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a72a20-c928-4bec-8831-1618f971be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "#### We now will build an optical system using an ordered dict data structure ####\n",
    "Optical_Path = OrderedDict()    \n",
    "\n",
    "# #Display an image and prop light 1 focal length to the lens. Each step gets assigned a name of your choice. \n",
    "# We adopt the convention that propagation steps begin with P, lenses with L, SLMs with S and absorption masks with A\n",
    "Optical_Path['P0'] = prop.ASM_Prop( wavelength = lamb,dx = dx, distance = 1*focal_length , N=s[0] , H=None, device = device)\n",
    "\n",
    "# #We apply a thin lens phase delay and propagate 1 more f to the fourier plane \n",
    "Optical_Path['L1'] = comp.Thin_Lens(f= 1*focal_length, wavelength=lamb, R2 = R2 , device = device )\n",
    "Optical_Path['P1'] = prop.ASM_Prop( wavelength = lamb,dx = dx , distance = 1*focal_length , N=s[0] , H=None, device = device)\n",
    "\n",
    "\n",
    "#At the Fourier plane we apply a low pass absorption mask. \n",
    "#We define the mask as transmitting 1 within a certain radius and transmitting 0 elsewhere\n",
    "mask= torch.ones(s)\n",
    "aperture_radius_sq = .25*torch.max( R2 )\n",
    "mask[R2> aperture_radius_sq] = 0\n",
    "\n",
    "#We set an absorption grating with this mask. Since we wont optimize for this variable\n",
    "#we will pass a True flag to fixed_pattern\n",
    "Optical_Path['A0'] = comp.Absorption_Mask( transmission = mask.clone(), fixed_pattern = True , device =device )\n",
    "\n",
    "\n",
    "# #Nex we propagate out of the fourier plane, through a second lens and to the detector\n",
    "Optical_Path['P2'] = prop.ASM_Prop( wavelength = lamb,dx =dx, distance = 1*focal_length , N=s[0] , padding = 0, H=None, device = device)\n",
    "Optical_Path['L2'] = comp.Thin_Lens(f= 1*focal_length, wavelength=lamb, R2 = R2  , device = device )\n",
    "Optical_Path['P3'] = prop.ASM_Prop( wavelength = lamb,dx = dx, distance = 1*focal_length , N=s[0] , padding = 0, H=None, device = device)\n",
    "\n",
    "#Once the Optical Path is defined we can combine it into a single network. \n",
    "four_f_model=torch.nn.Sequential( Optical_Path ).to(device)\n",
    "\n",
    "\n",
    "#View the results for both 'batch' images\n",
    "f,ax_arr = plt.subplots(2,2,figsize=(12,12))\n",
    "\n",
    "\n",
    "img = 0\n",
    "\n",
    "im_1 = ax_arr[0,0].imshow(( ( field_in[img,0,:,:]) ).abs().cpu().detach())\n",
    "ax_arr[0,1].imshow(( four_f_model( field_in)[img,0,:,:] ).abs().cpu().detach())\n",
    "\n",
    "ax_arr[0,0].set_title('Input field intensity')\n",
    "ax_arr[0,1].set_title('Output intensity of 4F system with aperture')\n",
    "\n",
    "ax_arr[0,0].axis('off')\n",
    "ax_arr[0,1].axis('off')\n",
    "\n",
    "img = 1\n",
    "\n",
    "ax_arr[1,0].imshow(( ( field_in[img,0,:,:]) ).abs().cpu().detach())\n",
    "ax_arr[1,1].imshow(( four_f_model( field_in)[img,0,:,:] ).abs().cpu().detach())\n",
    "\n",
    "ax_arr[1,0].set_title('Input field intensity')\n",
    "ax_arr[1,1].set_title('Output intensity of 4F system with aperture')\n",
    "\n",
    "ax_arr[1,0].axis('off')\n",
    "ax_arr[1,1].axis('off')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d604bbbe-9c77-4ac4-9164-b5d42673e990",
   "metadata": {},
   "source": [
    "Because a 4f system can be written as fourier transforms we can use the FT_Lens class to rewrite this in a more compact way. The FT approach to lenses has a different gird spacing at the observation and Fourier planes. When a method has a different grid spacing it is labeled with \"\\_NC\" (new coordinates) and contains the variable dx_new for the new grid spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1b4a0a-6340-4ee8-969a-e1f22ffeb95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set input images\n",
    "field_in[0,0,:,:] = ((1j)*image_noise_padding/255.0  ).to(device) \n",
    "field_in[1,0,:,:] = ((1j)*image_noise_padding2/255.0  ).to(device) \n",
    "\n",
    "####################################################\n",
    "\n",
    "#### We now will build an optical system using an ordered dict data structure ####\n",
    "Optical_Path_2 = OrderedDict()    \n",
    "\n",
    "#Prop light from the rear focal plane of a lens to the Fourier plane\n",
    "Optical_Path_2['FT0'] =  comp.FT_Lens_NC(f= focal_length, wavelength= lamb, dx = dx , N = s[0], device = device   )\n",
    "\n",
    "#At the Fourier plane we apply a low pass absorption mask but we need to do it in our rescaled coordinates\n",
    "\n",
    "#new grid spacing \n",
    "dx_new = Optical_Path_2['FT0'].dx_new \n",
    "\n",
    "#magnification factor \n",
    "mag = dx_new/dx\n",
    "\n",
    "#We set an absorption grating with this mask. Since we wont optimize for this variable\n",
    "#we will pass a True flag to fixed_pattern\n",
    "mask= torch.ones(s)\n",
    "aperture_radius_sq =  (.25 / (mag**2) ) *torch.max( R2 )\n",
    "mask[R2 > aperture_radius_sq] = 0\n",
    "Optical_Path_2['A0'] = comp.Absorption_Mask( transmission = mask.clone(), fixed_pattern = True , device =device )\n",
    "\n",
    "# #Display random pattern and prop light from fourier plane to observation plane. However we need to take into account the new\n",
    "#coordinates (NC) by adjusting dx\n",
    "Optical_Path_2['FT1'] =  comp.FT_Lens_NC(f= focal_length, wavelength= lamb, dx = dx_new , N = s[0], device = device   )\n",
    "\n",
    "\n",
    "#Once the Optical Path is defined we can combine it into a single network. \n",
    "four_f_model_2=torch.nn.Sequential( Optical_Path_2 ).to(device)\n",
    "\n",
    "\n",
    "#View the results \n",
    "f,ax_arr = plt.subplots(2,2,figsize=(12,12))\n",
    "\n",
    "\n",
    "img = 0\n",
    "\n",
    "ax_arr[0,0].imshow(( ( field_in[img,0,:,:]) ).abs().cpu().detach())\n",
    "ax_arr[0,1].imshow(( four_f_model_2( field_in)[img,0,:,:] ).abs().cpu().detach())\n",
    "\n",
    "ax_arr[0,0].set_title('Input field intensity')\n",
    "ax_arr[0,1].set_title('Output intensity of 4F system with aperture')\n",
    "\n",
    "ax_arr[0,0].axis('off')\n",
    "ax_arr[0,1].axis('off')\n",
    "\n",
    "img = 1\n",
    "\n",
    "ax_arr[1,0].imshow(( ( field_in[img,0,:,:]) ).abs().cpu().detach())\n",
    "ax_arr[1,1].imshow(( four_f_model_2( field_in)[img,0,:,:] ).abs().cpu().detach())\n",
    "\n",
    "ax_arr[1,0].set_title('Input field intensity')\n",
    "ax_arr[1,1].set_title('Output intensity of 4F system with aperture')\n",
    "\n",
    "ax_arr[1,0].axis('off')\n",
    "ax_arr[1,1].axis('off')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea977bfc-5c28-45c9-bfa7-9735a0131ac1",
   "metadata": {},
   "source": [
    "In this example we will optimize for a phase SLM pattern to display and image via diffraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45410fec-45cf-4a00-a073-ba69fa914e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting uo problem parameters \n",
    "\n",
    "# units\n",
    "mm = 1e-3\n",
    "nm = 1e-9\n",
    "\n",
    "\n",
    "## Setting Problem Parameters ##\n",
    "\n",
    "#Masking the initial field \n",
    "s= (800,800)      # size of simulation in pixels\n",
    "sim_size = 5*mm     # size of wavefront \n",
    "\n",
    "#coordinates \n",
    "x_c = torch.linspace(-sim_size/2,sim_size/2, s[0] )  #XCoordinates \n",
    "y_c = torch.linspace(-sim_size/2,sim_size/2, s[1] )  #YCoordinates \n",
    "[X,Y] = torch.meshgrid(x_c,y_c)    #Generate Coordinate Mesh\n",
    "R2= X**2 + Y**2                    #Radial coordinates\n",
    "dx = x_c[1] - x_c[0]                #grid spacing\n",
    "\n",
    "\n",
    "# Wavelength\n",
    "lamb  = 500.0* nm\n",
    "\n",
    "#Lens focal length\n",
    "focal_length = 30* mm \n",
    "\n",
    "#Detector distance\n",
    "detector_distance = 20* mm\n",
    "\n",
    "#Define output target image\n",
    "s2=( int( s[0]/2)  ,int( s[1]/2 ) )\n",
    "target_image = torch.tensor( np.array(Image.fromarray(imageio.imread('imageio:camera.png')).resize(s)), dtype =torch.cfloat ).to(device)\n",
    "\n",
    "#define the incident field as a delta function \n",
    "field_in = torch.zeros(s, dtype = torch.cfloat, requires_grad = False).to(device)\n",
    "field_in[ int(s[0]/2) - 3 : int(s[0]/2) + 3 , int(s[1]/2) - 3 : int(s[1]/2) + 3 ] = 1\n",
    "\n",
    "\n",
    "plt.imshow(target_image.abs().cpu())\n",
    "plt.title('Target output image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bc111a-8973-4bbb-8c40-05f5c7e05816",
   "metadata": {},
   "source": [
    "Our optical setup will consist of a point source going through a fourier transform lens and then propagated through a SLM to a detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4665d0-1bf0-4466-933a-30d2c3d844c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### We now will build an optical system using an ordered dict data structure ####\n",
    "Optical_Path_3 = OrderedDict()    \n",
    "\n",
    "# #Display random pattern and prop light from the rear focal plane of a lens to the Fourier plane\n",
    "Optical_Path_3['FT0'] =   comp.FT_Lens_NC(f= focal_length, wavelength= lamb, dx = dx , N = s[0] , device = device   )\n",
    "\n",
    "#At the Fourier plane we apply a phase SLM. The initial pattern is a random but we \n",
    "#will learn the phase delay later\n",
    "Optical_Path_3['S0'] = comp.SLM( phase_delay = 10* torch.rand(s).to(device) ,  device =device )\n",
    "\n",
    "# #Next we propagate out of the fourier plane, through a second lens and to the detector (our DX changed using a NC method)\n",
    "Optical_Path_3['P0'] = prop.ASM_Prop( wavelength = lamb,dx = Optical_Path_3['FT0'].dx_new, distance = 1*detector_distance , N=s[0] , H=None, device = device)\n",
    "\n",
    "\n",
    "#Once the Optical Path is defined we can combine it into a single network. \n",
    "diffraction_model=torch.nn.Sequential( Optical_Path_3 ).to(device)\n",
    "\n",
    "\n",
    "#View the results \n",
    "f,ax_arr = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "ax_arr[0].imshow(( field_in[:,:] ).abs().cpu().detach())\n",
    "ax_arr[1].imshow(diffraction_model( field_in)[:,:] .abs().cpu().detach()) \n",
    "\n",
    "ax_arr[0].set_title('Input field intensity')\n",
    "ax_arr[1].set_title('Output intensity of 4F system with aperture')\n",
    "\n",
    "ax_arr[0].axis('off')\n",
    "ax_arr[1].axis('off')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac7f3aa-ed3e-4833-87e5-c756e00c8da9",
   "metadata": {},
   "source": [
    "Tocohpy arranges optical paths similarly to a Neural network. All components are on the data graph and gradients can be back propagated through allowing for optimization using pytorch optimizers. Unless fixed_pattern =True the SLM class will always contain learnable parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21ee5b1-8227-4fa8-95cb-ad451c93a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### To optimize for the diffraction grating we use a loop structure very similar to optimizing a Neural network ####\n",
    "#We select our optimizer for the model parameters. Currently, SLM and Absorption Gratings have learnable patterns by default\n",
    "\n",
    "optimizer = torch.optim.Adam(diffraction_model.parameters() , lr=0.5)\n",
    "\n",
    "#Rescale target image to match incident light budget \n",
    "\n",
    "light_budget = torch.norm( field_in )\n",
    "target_image = light_budget * target_image /torch.norm( target_image) \n",
    "\n",
    "#Loop and optimize\n",
    "for t in range(1000):\n",
    "\n",
    "    #L2: Compute and print loss\n",
    "    L_fun = 1*( diffraction_model(field_in).abs() - target_image.abs() ).std() \n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    L_fun.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "    if t % 100 == 1:\n",
    "        print(t, 'Loss:' , L_fun.item() ) \n",
    "\n",
    "##\n",
    "##Examine the results\n",
    "##\n",
    "f, ax = plt.subplots(1,4,figsize=(22,12))\n",
    "\n",
    "im1=ax[0].imshow(field_in.abs().detach().cpu() )\n",
    "im2=ax[1].imshow( list(diffraction_model.parameters() )[0].clone().detach().abs().cpu())\n",
    "im2=ax[2].imshow( diffraction_model(field_in)[:,:].clone().detach().abs().cpu())\n",
    "im1=ax[3].imshow(target_image.abs().detach().cpu() )\n",
    "\n",
    "\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "ax[2].axis('off')\n",
    "ax[3].axis('off')\n",
    "\n",
    "ax[0].set_title('Input field at 0', fontsize = 20)\n",
    "ax[1].set_title('SLM pattern at Fourier plane', fontsize = 20)\n",
    "ax[2].set_title('Detected image', fontsize = 20)\n",
    "ax[3].set_title('Target image', fontsize = 20)             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5023c9e0-0635-4005-a841-f5d9672d316d",
   "metadata": {},
   "source": [
    "Optical Neural Networks are a topic which has become increasingly popular. Several papers use SBN and other nonlinear crystals. Tocohpy allows for Split step propagation for solving the Nonlinear shrondinger equation. Gradients can still be propagated through these nonlinear methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285df460-5761-4e6f-8de9-e09f292c6ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# units\n",
    "mm = 1e-3\n",
    "nm = 1e-9\n",
    "\n",
    "\n",
    "## Setting Problem Parameters ##\n",
    "\n",
    "#Masking the initial field \n",
    "s= (800,800)        # size of simulation in pixels\n",
    "sim_size = 5*mm     # size of wavefront \n",
    "\n",
    "#coordinates \n",
    "x_c = torch.linspace(-sim_size/2,sim_size/2, s[0] )  #XCoordinates \n",
    "y_c = torch.linspace(-sim_size/2,sim_size/2, s[1] )  #YCoordinates \n",
    "[X,Y] = torch.meshgrid(x_c,y_c)    #Generate Coordinate Mesh\n",
    "R2= X**2 + Y**2                    #Radial coordinates\n",
    "dx = x_c[1] - x_c[0]               #grid spacing\n",
    "\n",
    "\n",
    "# Wavelength\n",
    "lamb  = 500.0* nm\n",
    "\n",
    "#Lens focal length\n",
    "focal_length = 50* mm \n",
    "\n",
    "#distance from SLM to Crystal\n",
    "crystal_distance = 100* mm\n",
    "\n",
    "#Distance from crystal Detector\n",
    "detector_distance = 100* mm\n",
    "\n",
    "#Define output target image\n",
    "s2=( int( s[0]/2)  ,int( s[1]/2 ) )\n",
    "target_image = torch.tensor( np.array(Image.fromarray(imageio.imread('imageio:camera.png')).resize(s)), dtype =torch.cfloat ).to(device)\n",
    "\n",
    "#define the incident field as a delta function \n",
    "field_in = torch.zeros(s, dtype = torch.cfloat, requires_grad = False).to(device)\n",
    "field_in[ int(s[0]/2) - 3 : int(s[0]/2) + 3 , int(s[1]/2) - 3 : int(s[1]/2) + 3 ] = 1\n",
    "\n",
    "# # We now set the parameters of the nonlinear crystal\n",
    "gamma = -500\n",
    "crystal_length = 10* mm\n",
    "num_steps = 50\n",
    "h = crystal_length / num_steps \n",
    "\n",
    "\n",
    "####################################################\n",
    "\n",
    "#### We now will build an optical system using an ordered dict data structure ####\n",
    "Optical_Path_NLS = OrderedDict()    \n",
    "\n",
    "# #Display random pattern and prop light from the rear focal plane of a lens to the Fourier plane\n",
    "Optical_Path_NLS['FT0'] =  comp.FT_Lens_NC(f= focal_length, wavelength= lamb, dx = dx , N= s[0], device = device  )\n",
    "\n",
    "#At the Fourier plane we apply a low pass absorption mask\n",
    "Optical_Path_NLS['S0'] = comp.SLM( phase_delay = torch.rand(s).to(device) ,  device =device )\n",
    "\n",
    "# March light through SB crystal (1cm thick) with opterator splitting\n",
    "for i in range(0,num_steps):\n",
    "    Optical_Path_NLS['Cp' + str(i)] = prop.NLS_Prop( wavelength = lamb,dx = x_c[1] - x_c[0], distance = 1*h , N=s[0] , H=None, padding = 1/8,  device = device)\n",
    "    Optical_Path_NLS['Cu' + str(i)] =comp.SB_Crystal_Update( gamma=gamma , distance = h, device = device  )\n",
    "    \n",
    "#Nex we propagate out of the fourier plane, through a second lens and to the detector\n",
    "Optical_Path_NLS['P0'] = prop.ASM_Prop( wavelength = lamb,dx = x_c[1] - x_c[0], distance = 1*detector_distance , N=s[0] , H=None, device = device)\n",
    "\n",
    "#Once the Optical Path is defined we can combine it into a single network. \n",
    "crystal_model=torch.nn.Sequential( Optical_Path_NLS ).to(device)\n",
    "\n",
    "\n",
    "\n",
    "#View the results \n",
    "f,ax_arr = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "ax_arr[0].imshow(( ( field_in) ).abs().cpu().detach())\n",
    "ax_arr[1].imshow( (crystal_model( field_in )[:,:]  ) .abs().cpu().detach()) \n",
    "\n",
    "ax_arr[0].set_title('Input field intensity')\n",
    "ax_arr[1].set_title('Output intensity of 4F system with aperture')\n",
    "\n",
    "ax_arr[0].axis('off')\n",
    "ax_arr[1].axis('off')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052b838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### To optimize for the diffraction grating we use a loop structure very similar to optimizing a Neural network ####\n",
    "\n",
    "optimizer = torch.optim.Adam(crystal_model.parameters() , lr=0.35)\n",
    "\n",
    "#Rescale target image to match incident light budget \n",
    "light_budget = torch.norm( field_in )\n",
    "target_image = light_budget * target_image /torch.norm( target_image) \n",
    "\n",
    "#Loop and optimize\n",
    "for t in range(500):\n",
    "\n",
    "    \n",
    "    #L2: Compute and print loss\n",
    "    L_fun = 1*( crystal_model(field_in).abs() - target_image.abs() ).std() \n",
    "\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "\n",
    "        # Backpropagation\n",
    "                #zero my grads out\n",
    "    optimizer.zero_grad()\n",
    "    L_fun.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "    if t % 100 == 1:\n",
    "        print(t, 'Loss:' , L_fun.item() ) \n",
    "        \n",
    "        \n",
    "##\n",
    "##Examine the results\n",
    "##\n",
    "f, ax = plt.subplots(1,4,figsize=(22,12))\n",
    "\n",
    "im1=ax[0].imshow(field_in.abs().detach().cpu() )\n",
    "im2=ax[1].imshow( list(crystal_model.parameters() )[0].clone().detach().abs().cpu())\n",
    "im2=ax[2].imshow( crystal_model(field_in)[:,:].clone().detach().abs().cpu())\n",
    "im1=ax[3].imshow(target_image.abs().detach().cpu() )\n",
    "\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "ax[2].axis('off')\n",
    "ax[3].axis('off')\n",
    "\n",
    "ax[0].set_title('Input field at 0', fontsize = 20)\n",
    "ax[1].set_title('SLM pattern at Fourier plane', fontsize = 20)\n",
    "ax[2].set_title('Detected image', fontsize = 20)\n",
    "ax[3].set_title('Target image', fontsize = 20)         \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d45f81f-53fc-4504-bc0d-fbc4f8ed7fa2",
   "metadata": {},
   "source": [
    "In some holography applications, it may be necessary to have some components which are learned for entire batches of images and some components which are learned for specific images. This can be accomplished by adding or using batch/channel dimensions to learnable optical components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff3f4eb-f582-4bf1-b03a-ffc406875291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# units\n",
    "mm = 1e-3\n",
    "nm = 1e-9\n",
    "\n",
    "\n",
    "## Setting Problem Parameters ##\n",
    "\n",
    "#Masking the initial field \n",
    "s= (100,100)      # size of simulation in pixels\n",
    "sim_size = 5*mm     # size of wavefront \n",
    "\n",
    "#coordinates \n",
    "x_c = torch.linspace(-sim_size/2,sim_size/2, s[0] )  #XCoordinates \n",
    "y_c = torch.linspace(-sim_size/2,sim_size/2, s[1] )  #YCoordinates \n",
    "[X,Y] = torch.meshgrid(x_c,y_c)    #Generate Coordinate Mesh\n",
    "R2= X**2 + Y**2                    #Radial coordinates\n",
    "dx = x_c[1] - x_c[0]                #grid spacing\n",
    "\n",
    "\n",
    "# Wavelength\n",
    "lamb  = 500.0* nm\n",
    "\n",
    "#Lens focal length\n",
    "focal_length = 100* mm \n",
    "\n",
    "#distance from SLM to Crystal\n",
    "crystal_distance = 40* mm\n",
    "\n",
    "#Distance from crystal Detector\n",
    "detector_distance = 100* mm\n",
    "\n",
    "#Define output target image\n",
    "s2=( int( s[0]/2)  ,int( s[1]/2 ) )\n",
    "target_image=torch.rand(10,3,s[0],s[1]).to(device)\n",
    "\n",
    "#define the incident field as a delta function \n",
    "field_in = torch.zeros(s, dtype = torch.cfloat, requires_grad = False).to(device)\n",
    "field_in[ int(s[0]/2) - 3 : int(s[0]/2) + 3 , int(s[1]/2) - 3 : int(s[1]/2) + 3 ] = 1\n",
    "\n",
    "\n",
    "####################################################\n",
    "\n",
    "#### We now will build an optical system using an ordered dict data structure ####\n",
    "Optical_Path_Batch = OrderedDict()    \n",
    "\n",
    "#Prop inpput field\n",
    "Optical_Path_Batch['P0'] = prop.ASM_Prop( wavelength = lamb,dx = x_c[1] - x_c[0], distance = 1*focal_length , N=s[0] , H=None, device = device)\n",
    "\n",
    "# apply lens\n",
    "Optical_Path_Batch['L0'] = comp.Thin_Lens(f= 1*focal_length, wavelength=lamb, R2 = R2  , device = device )        \n",
    "    \n",
    "    \n",
    "#Prop light \n",
    "Optical_Path_Batch['P1'] = prop.ASM_Prop( wavelength = lamb,dx = x_c[1] - x_c[0], distance = 1*focal_length , N=s[0] , H=None, device = device)\n",
    "\n",
    "\n",
    "#SLM learns 1 pattern for all inputs (Controlled by the shape of phase delay)\n",
    "Optical_Path_Batch['S0'] =comp.SLM( phase_delay = torch.rand(s).to(device) ,  device =device )\n",
    "\n",
    "#Prop light\n",
    "Optical_Path_Batch['P2'] = prop.ASM_Prop( wavelength = lamb,dx = x_c[1] - x_c[0], distance = 1*focal_length , N=s[0] , H=None, device = device)\n",
    "\n",
    "#BATCH SLM learns a different pattern for each of the 10 inputs but 1 pattern per channel \n",
    "Optical_Path_Batch['S1'] =comp.SLM( phase_delay = torch.rand( 10, 1 , s[0],s[1] ).to(device) ,  device =device )\n",
    "\n",
    "#Prop light \n",
    "Optical_Path_Batch['P3'] = prop.ASM_Prop( wavelength = lamb,dx = x_c[1] - x_c[0], distance = 1*focal_length-crystal_length , N=s[0] , H=None, device = device)\n",
    "\n",
    "#apply lens \n",
    "Optical_Path_Batch['L1'] = comp.Thin_Lens(f= 1*focal_length, wavelength=lamb, R2 = R2 ,  device = device )        \n",
    "    \n",
    "    \n",
    "#prop to detector\n",
    "Optical_Path_Batch['P4'] = prop.ASM_Prop( wavelength = lamb,dx = x_c[1] - x_c[0], distance = 1*focal_length , N=s[0] , H=None, device = device)\n",
    "\n",
    "\n",
    "\n",
    "Batch_SLM_Model=torch.nn.Sequential( Optical_Path_Batch ).to(device)\n",
    "\n",
    "\n",
    "\n",
    "#View the a sample of results \n",
    "f,ax_arr = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "chan = 0\n",
    "batch = 3\n",
    "\n",
    "ax_arr[0].imshow(( ( target_image[batch,chan,:,:]) ).abs().cpu().detach())\n",
    "ax_arr[1].imshow(( Batch_SLM_Model( target_image )[batch,chan,:,:].abs()).cpu().detach()) \n",
    "\n",
    "ax_arr[0].set_title('Input field intensity')\n",
    "ax_arr[1].set_title('Output intensity of 4F system with aperture')\n",
    "\n",
    "ax_arr[0].axis('off')\n",
    "ax_arr[1].axis('off')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ONN",
   "language": "python",
   "name": "onn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
