{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695faf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Copyright (c) 2022 Meta Platforms, Inc. and affiliates\n",
    "#\n",
    "# Holotorch is an optimization framework for differentiable wave-propagation written in PyTorch \n",
    "# This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\n",
    "#\n",
    "# Contact:\n",
    "# florianschiffers (at) gmail.com\n",
    "# ocossairt ( at ) fb.com\n",
    "#\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4a4bc",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import os, sys, torch, glob, urllib, zipfile, pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(os.getcwd())\n",
    "sys.path.append('..\\\\') # Make sure holotorch_internal is imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775470e7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import holotorch.CGH_Datasets.Single_Image_Dataset as Single_Image_Dataset\n",
    "import holotorch.CGH_Datasets.Factory_Dataset as Factory_Dataset\n",
    "from holotorch.CGH_Datatypes.IntensityField import IntensityField\n",
    "from holotorch.ComponentWrapper.PARAM_DATASET import PARAM_DATASET\n",
    "from holotorch.utils.Enumerators import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3647926",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'scroll': True,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a904be8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Holotorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f05a2e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## differentiable coherent light transport in PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8624ff38",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Main Developer: Florian Schiffers$^{1,2}$, Oliver Cossairt$^{1,2}$\n",
    "\n",
    "Co-Developer: Grace Kuo$^2$, Lionel Fiske$^{1,2}$, Praneeth Chakravarthula$^3$, Ethan Tseng$^3$, Seung-Hwan Baek$^{3,4}$, Gang Li$^2$, Jipeng Zhang$^2$, Andrew Maimone$^2$, Felix Heide $^3$, Doug Lanman$^3$, Nathan Matsuda$^2$\n",
    "\n",
    "$^1$: Northwestern University\n",
    "$^2$: META Reality Labs\n",
    "$^3$: Princeston University\n",
    "$^4$: POSTECH\n",
    "\n",
    "Contact: florian.schiffers@u.northwestern.edu | olivercossairt@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108ca5ad",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "GitHub Link: TO BE CREATED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4f545f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is Holotorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74e680",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Holotorch provides an easy to customize optimization toolkit for holographic display systems based on Automatic Differentiation (PyTorch) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f057acf",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Abstracted optimization framework based on PyTorch Lightning (which e.g. enables simple Multi-GPU support)\n",
    "- Pre-implemented dataset-classes (2D images, focal stack) with automated pre-loading to RAM/GPU\n",
    "- Datatypes for electric fields (storing spectral and spatial information) and easy visualization methods\n",
    "- Many pre-built optical components/propagators that allow to assemble an optical path for forward modeling\n",
    "- Streamlined optimization routines + logging/saving of information, plots etc.\n",
    "- Hardware implementations for Camera (Ximea, Flir) and Display (using slmPy)\n",
    "    - Capture routines to create datasets for Setup Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3ff451",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why do you want to use Holotorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a585b35",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Beginners: Easy to way to get started in the world of Computer Generated Holography without having to write a lot code\n",
    "- Researchers: Fast prototyping of new optical models without “reinventing the wheel”\n",
    "- Tested functions for coherent light-transport (ASM, Fresnel, HOEs, FT-lens integrated with wavelength depedency)\n",
    "- “Click through” example-notebooks for many existing components and setups in the framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed67511d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What have we implemented (a few examples)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474fb108",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Double-Phase Encoding (DPAC)\n",
    "- Phase-Retrieval for Near-Eye (ASM) and Far-Field (Fourier) Holography \n",
    "- (Neural) Etendue Expansion\n",
    "- Partially Coherent Holography\n",
    "- Camera-in-the-Loop (full documentation + example dataset in the next iteration of holotorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9489d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fddd967",
   "metadata": {},
   "source": [
    "In holotorch we're using SI units for everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e788bc88",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import holotorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1628c0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from holotorch.utils.units import * # E.g. to get nm, um, mm etc.\n",
    "print(\"10mm : \", 10*mm, \"in m\")\n",
    "print(\" 1nm : \", 1*nm, \"in m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca4e14",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " ### Let's introduce the electric field module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b28dcb",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from holotorch.CGH_Datatypes.ElectricField import ElectricField\n",
    "# ElectricFields are 6D objects: \n",
    "# B x T x P x C x H x W\n",
    "# BATCH x TIME x PUPIL (lightfields) x Channel (Wavelength) x Height x Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf8b77",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "N = 1024\n",
    "field_data = torch.zeros(1,1,1,1,N,N) + 0j # 0j to make it complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732a588d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Set ones to the field\n",
    "field_data[...,N//4 : 3 * N//4, N//4 : 3 * N//4] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68c91d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Cast into our Holotorch Datatype\n",
    "field_input = ElectricField(\n",
    "    data = field_data, \n",
    "    wavelengths = 532 * nm,\n",
    "    spacing = 8 * um,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64c88ee",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "field_input.visualize(flag_axis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8032f9b5",
   "metadata": {},
   "source": [
    "Plotting can take a lot of time if the image size is large.\n",
    "<br>\n",
    "We can reduce the rendering time by downsampling our fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b4a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(field_input.spacing)\n",
    "print(field_input.shape)\n",
    "downsampled_field = field_input.rescale(0.25)\n",
    "print(downsampled_field.spacing)\n",
    "print(downsampled_field.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8317fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_field.visualize(flag_axis=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4751ad18",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ASM - Propagator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d68eb7",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "$$\n",
    "E(x, y, z)=\\iint_{-\\infty}^{\\infty} \\hat{E}\\left(f_{x}, f_{y}, 0\\right) e^{i k z \\sqrt{1-\\lambda^{2}\\left(f_{x}^{2}+f_{y}^{2}\\right)} e^{i 2} \\pi\\left(f_{x} x+f_{y} y\\right)} d f_{x} d f_{y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd7b2d5",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "$$\n",
    "E\\left(x, y, z_{2}\\right)=\\mathcal{F}^{-1}\\left\\{\\mathcal{F}\\left\\{E\\left(x, y, z_{1}\\right)\\right\\} * \\mathcal{F}\\left\\{H\\left(x, y, z_{2}-z_{1}\\right)\\right\\}\\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22284f71",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "$$\n",
    " \\hat{H}(f_x, f_y) = e^{i k z \\sqrt{1-\\lambda^{2}\\left(f_{x}^{2}+f_{y}^{2}\\right)}} \n",
    " $$\n",
    " $$\\text{ or with fresnel approximation } \n",
    " $$\n",
    " $$\n",
    " \\hat{H}(f_x, f_y)_{\\text{Fresnel}} = e^{i kz ( 1 + \\frac{ f_{x}^{2}+f_{y}^{2} }{2k}  ) } \n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc951fd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ASM - Propagator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12040585",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from holotorch.Optical_Propagators.ASM_Prop import ASM_Prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e1a239",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "asm_prop = ASM_Prop(\n",
    "    init_distance = 50*mm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e66e5c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Cast data into Holotorch datatype \n",
    "field_propagated = asm_prop.forward(\n",
    "    field = field_input\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dc8122",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's visualize the propagated field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a0033c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(121)\n",
    "field_input.visualize(rescale_factor = 0.25, flag_colorbar=True,\n",
    "                      flag_axis= True, title = \"Input Field\")\n",
    "plt.subplot(122)\n",
    "field_propagated.visualize(rescale_factor = 0.25,flag_colorbar=True,\n",
    "                           flag_axis=True, title = \"Output Field\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db01d805",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## We can also visualize the ASM-kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707bb0a0",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's reset the propagation distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15cb1b0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "asm_prop.z = 100*mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59caf0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "asm_prop.visualize_kernel(field = field_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2fdcb9",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "What happens if we choose an even larger propagation distance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca04066",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "asm_prop.z = 250*mm\n",
    "# Long propagation lead to quicker aliasing of propagation kernel\n",
    "# These frequencies are not supported by our grid,\n",
    "# hence we need to bandlimit the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a60dff",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "asm_prop.visualize_kernel(field = field_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677b2f73",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Build a 4F system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1577b9",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center><img src=\"images/four_4_system.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3ac4e1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Build a 4F system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7601db7",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Import a Fourier Lens Component\n",
    "from holotorch.Optical_Components.FT_Lens import FT_Lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57711abc",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Define the lenses in our 4f-system\n",
    "lens1 = FT_Lens(focal_length  = 50 * mm)\n",
    "lens2 = FT_Lens(focal_length  = 100 * mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357b3b66",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "N      = 1024   # Number of pixel of our image\n",
    "# Create an image\n",
    "field_data = torch.zeros(1,1,1,1,N,N) + 0j # 0j to make it complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c51bdd4",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Let's create a white rectangle in the center of our image\n",
    "center = N//2   # Compute the center\n",
    "size   = 20  \n",
    "# Set ones to the field\n",
    "field_data[..., center - size : center + size,\n",
    "               center - size : center + size ] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a9b8d3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Cast into our Holotorch Datatype\n",
    "field_input = ElectricField(\n",
    "    data        = field_data,\n",
    "    wavelengths = 532 * nm,\n",
    "    spacing     = 8 * um,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f4cff9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "field_input.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2b0d8b",
   "metadata": {},
   "source": [
    "Pass the field through both lenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29763bf2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fourier_plane = lens1(field_input)\n",
    "four_f_plane  = lens2(fourier_plane)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b2e8f7",
   "metadata": {},
   "source": [
    "Let's have a look at the spacing at the various planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1647e4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Spacing at Input Plane: \",  \"%.2f\" % (float(field_input.spacing.data_tensor[...,0]) / um), \"um\")\n",
    "print(\"Spacing at Fourier Plane\", \"%.2f\" % (float(fourier_plane.spacing.data_tensor[...,0]) / um), \"um\")\n",
    "print(\"Spacing at 4f-Plane: \",  \"%.2f\" % (float(four_f_plane.spacing.data_tensor[...,0]) / um), \"um\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94076722",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Visualize our 4f system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e197efcb",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "plt.subplot(131)\n",
    "field_input.visualize(rescale_factor=0.25, title=\"Input Field\", flag_axis= True)\n",
    "plt.subplot(132)\n",
    "fourier_plane.visualize(rescale_factor=0.25,flag_log = False, title= \"Fourier Plane\", flag_axis= True)\n",
    "plt.subplot(133)\n",
    "four_f_plane.visualize(rescale_factor=0.25,title = \"4F Plane (magnified)\", flag_axis= True)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6411d6d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Use the Built In 4F system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e6ef5d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Import a Fourier Lens Component\n",
    "from holotorch.Optical_Components.Four_F_system import Four_F_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83771e3",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "four_f_system = Four_F_system(\n",
    "    focallength_1   = 100 * mm,\n",
    "    focallength_2   = 200 * mm,\n",
    "    aperture_radius = 0.25 * mm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6200ac94",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Use Single_Image_Dataset to read and process and image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4089066",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from holotorch.CGH_Datasets.Single_Image_Dataset import Single_Image_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c62bc42",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dataset = Single_Image_Dataset(\n",
    "    path        = \"..//ExampleImages//tiger.png\",\n",
    "    num_pixel_x = 512,\n",
    "    num_pixel_y = 512,\n",
    "    grayscale   = True,\n",
    ") # Dataset spits out a 5D-tensor (TPCHW, but no batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee27608",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "print(data.shape)\n",
    "data = data[None]\n",
    "# We need to extend the batch dimension since a dataset returns 1 image at a time\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805524ad",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "electric_field : ElectricField = ElectricField(\n",
    "    data        = data,\n",
    "    wavelengths = 532 * nm,\n",
    "    spacing     = 8 * um\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c93bcf",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "electric_field.visualize(flag_axis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6cbd3f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Pass the electrical field into the four 4 system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb56434",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "four_f_system = Four_F_system(\n",
    "    focallength_1   = 100 * mm,\n",
    "    focallength_2   = 200 * mm,\n",
    "    aperture_radius = 0.15 * mm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4c297b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "field_out = four_f_system( field = electric_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c9493",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "four_f_system.aperture.visualize() \n",
    "# We use abberations in the same way was aperture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe5396",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Note how the spacing automatically changed\n",
    "# Holotorch is internally keeping track of the correct spacing!\n",
    "print(float(electric_field.spacing.data_tensor[...,0]/um),\"um\")\n",
    "print(float(field_out.spacing.data_tensor[...,0]/um),\"um\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b391f1d5",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(121)\n",
    "electric_field.visualize(title = \"Input Field\", flag_axis= True)\n",
    "plt.subplot(122)\n",
    "field_out.visualize(title = \"Output Field\", flag_axis= True)\n",
    "plt.tight_layout() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74428df7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Double-Phase-Amplitude-Encoding for Phase-Only Holography"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a17711",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "First we reload the image, but this time with non-square dimensions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de943aa3",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dataset = Single_Image_Dataset(\n",
    "    path        = \"..//ExampleImages//tiger.png\",\n",
    "    num_pixel_x = 1000,\n",
    "    num_pixel_y = 1400,\n",
    "    grayscale   = True,\n",
    ") # Dataset spits out a 5D-tensor (TPCHW, but no batch )\n",
    "\n",
    "electric_field : ElectricField = ElectricField(\n",
    "    data        = dataset[0][None],\n",
    "    wavelengths = 532 * nm,\n",
    "    spacing     = 8 * um\n",
    "    )\n",
    "\n",
    "electric_field.visualize(figsize=(10,10), flag_axis=True)\n",
    "electric_field.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12058fe5",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Use the DPAC-class to compute the DPAC-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3fd69d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from holotorch.Optical_Components.DPAC import DPAC\n",
    "dpac_generator = DPAC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79272746",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "phase_modulation = dpac_generator.compute_dpac_phase(\n",
    "                        target_field = electric_field,\n",
    "                        max_phase   = 2*np.pi \n",
    "                        # Max phase that our SLM supports \n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f88d7b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the electrical field\n",
    "field = torch.exp(1j * phase_modulation[:,:,None])\n",
    "# We need to expand the pupil dimension (SLM output is 5D)\n",
    "print(field.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54692ab",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Parse into an electrical field\n",
    "dpac_field = ElectricField(\n",
    "    data        = field,\n",
    "    wavelengths = 532 * nm,\n",
    "    spacing     = 8 * um\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4ec291",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Visualize the DPAC encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3785f646",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(121)\n",
    "electric_field[...,800:900,600:700].abs().visualize(\n",
    "    flag_axis=True, title = \"Target\")\n",
    "plt.subplot(122)\n",
    "dpac_field[...,800:900,600:700].angle().visualize(\n",
    "    flag_axis=True, title = \"DPAC encoded\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ce87f",
   "metadata": {},
   "source": [
    "Initialize the 4-f system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70845d8",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "four_f_system = Four_F_system(\n",
    "    focallength_1   = 100 * mm,\n",
    "    focallength_2   = 100 * mm,\n",
    "    aperture_radius = 2.5 * mm,\n",
    "    flag_flip       = True, \n",
    "    # Performs the automatic flip for better visualization\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c2c8c8",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Send the DPAC-encoded field through the 4f-system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba1370c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "field_out = four_f_system.forward( field = dpac_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a68069d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "four_f_system.aperture.visualize(figsize=(14,5), flag_colorbar = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ac19f1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What if we want to see what's happening inside the path?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1ab4dc",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "All we need to do is call \"add_output_hook\" at the corresponding component to visualizing anything happening anywhere inside the path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb723db",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "four_f_system.aperture.add_output_hook()\n",
    "four_f_system.lens1.add_output_hook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ec7ba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, we just need to call the model again (since we need to populate the outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21516b8",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "field_out = four_f_system( field = dpac_field)\n",
    "# Once an output hook is added,\n",
    "# every intermediate output will be appended to a list\n",
    "fourier_plane                 = four_f_system.lens1.outputs[-1] \n",
    "fourier_plane_after_aperture  = four_f_system.aperture.outputs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c1166",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "clear the outputs and delete the handle if no longer needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2400aa10",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "four_f_system.aperture.clear_outputs()\n",
    "four_f_system.lens1.clear_outputs()\n",
    "four_f_system.lens1.remove_output_hook()\n",
    "four_f_system.aperture.remove_output_hook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d116e9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's have a look at the intermediate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3ba55c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(fourier_plane.shape)\n",
    "print(fourier_plane_after_aperture.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2adab4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "plt.subplot(121)\n",
    "fourier_plane.abs().log().visualize(flag_colorbar = False, flag_axis= True, title='Before Filter')\n",
    "fourier_plane_abs = fourier_plane_after_aperture.abs()\n",
    "plt.subplot(122)\n",
    "fourier_plane_after_aperture.abs().log().visualize(flag_colorbar = False, flag_axis= True, title ='After Filter')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ae5021",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can even adjust the aspect ratio automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96da4444",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "fourier_plane.abs().log().visualize(flag_colorbar = False, flag_axis= True, adjust_aspect = True, title='Before Filter')\n",
    "fourier_plane_abs = fourier_plane_after_aperture.abs()\n",
    "plt.subplot(122)\n",
    "fourier_plane_after_aperture.abs().log().visualize( flag_colorbar = False, flag_axis= True, adjust_aspect = True, title ='After Filter')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791e59d5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's look at the final DPAC results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bcc513",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_out = four_f_system( field = dpac_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1614c0b8",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "plt.subplot(121)\n",
    "dpac_field.rescale(0.5).angle().visualize(flag_axis= True, title = \"DPAC field\")\n",
    "plt.subplot(122)\n",
    "field_out.rescale(0.5).visualize(flag_axis= True, title = \"Reconstructed image after DPAC filter\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0641ce43",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Build a simple phase-retrieval algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e5a6e1",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center><img src=\"images/asm_phase_retrieval.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5719bb4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Build a simple phase-retrieval algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7166dd",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Import a few holotorch modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d615f11f",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from holotorch.LightSources.CoherentSource import CoherentSource\n",
    "from holotorch.Spectra.WavelengthContainer import WavelengthContainer\n",
    "from holotorch.Spectra.SpacingContainer import SpacingContainer\n",
    "import holotorch.utils.Dimensions as Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f4cb49",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Define a source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500e4164",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "source = CoherentSource.create(\n",
    "    height      = 1000,\n",
    "    width       = 1400,\n",
    "    spacing     = 8 * um,\n",
    "    wavelengths = [432 * nm, 530 * nm, 630 * nm],\n",
    ")\n",
    "\n",
    "# Let's look at the output of our source\n",
    "source()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ad28a3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Import the Phase-Only SLM Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc66689",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from holotorch.HolographicComponents.SLM_PhaseOnly import SLM_PhaseOnly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e4c9e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Create the SLM object\n",
    "slm_model = SLM_PhaseOnly.create_slm(\n",
    "            height          = source.height,\n",
    "            width           = source.width,\n",
    "            n_channel       = source.num_channels,\n",
    "            feature_size    = source.grid_spacing.data_tensor[...,0],\n",
    "            init_type       = ENUM_SLM_INIT.RANDOM,\n",
    "            init_variance   = 0.1*np.pi,\n",
    "            )\n",
    "\n",
    "print(slm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c00bfb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Visualize the SLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ce4ddb",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "slm_model.visualize_slm(figsize=(15,5), wavelengths = source.wavelengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149bad96",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Create the Propagator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3c2441",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Define the propagator\n",
    "asm_prop = ASM_Prop(\n",
    "    init_distance = 50*mm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be24fdc7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Create a detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b355379",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from holotorch.Sensors.Detector import Detector\n",
    "# Define the detector\n",
    "detector = Detector(\n",
    "    color_flag = ENUM_SENSOR_TYPE.TIME_MULTIPLEXED,\n",
    "    N_pixel_out_x = source.height, # For simplicity we keep input / output the same\n",
    "    N_pixel_out_y = source.width, # For simplicity we keep input / output the same\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea504c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Assemble the  complete model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc9405f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First let's define a NearFieldHologram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec218e17",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from holotorch.Optical_Setups.Base_Setup import Base_Setup\n",
    "class NearFieldHologram(Base_Setup):\n",
    "    \"\"\"\n",
    "    NearFieldHologram is a torch-forward model implementing a\n",
    "    simple optical setup with ASM propagation \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "            source          : CoherentSource,\n",
    "            detector        : Detector,\n",
    "            slm             : SLM_PhaseOnly,\n",
    "            propagator      : ASM_Prop,\n",
    "            ) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.source      = source\n",
    "        self.detector    = detector\n",
    "        self.slm         = slm\n",
    "        self.propagator  = propagator\n",
    "    \n",
    "    def forward(self) -> IntensityField:\n",
    "        field = self.source()\n",
    "        field = self.slm(field)\n",
    "        field = self.propagator(field)\n",
    "        intensity = self.detector(field)\n",
    "        return intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c007ff",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's pass in our components and create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e90b7b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "hologram_model = NearFieldHologram(\n",
    "    source     = source,\n",
    "    detector   = detector,\n",
    "    slm        = slm_model,\n",
    "    propagator = asm_prop\n",
    ")\n",
    "hologram_model = hologram_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177f8e42",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Print out the paramter that will be optimized\n",
    "hologram_model.print_param_nice()\n",
    "# The _scale parameter is a secret \"sauce\" which is useful\n",
    "# for optimization with phase-only SLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8617bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hologram_model.print_state_dict_nice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc45efad",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model_out = hologram_model.forward()\n",
    "model_out.visualize(figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7b2110",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Optimize SLM - Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b7a0b6",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Step 1: Create the Torch Datamodule\n",
    "<br>\n",
    "<font size=\"3\">NOTE: Pytorch-Lightning Datamodules are similair to Torch Dataloaders</br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499442fa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from holotorch.CGH_Datasets.Single_Image_Dataset import Single_Image_Dataset\n",
    "from holotorch.CGH_Datasets.HoloDataModule import HoloDataModule\n",
    "\n",
    "dataset = Single_Image_Dataset(\n",
    "    path = \"..//ExampleImages//tiger.png\",\n",
    "    num_pixel_x = detector.N_pixel_out_x,\n",
    "    num_pixel_y = detector.N_pixel_out_y,\n",
    "    grayscale = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e1d8ca",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Create the datamodule\n",
    "datamodule = HoloDataModule(dataset = dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e925d168",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Get the intensity-field (which will be used as our target)\n",
    "image = datamodule.get_batch_IF(batch_idx=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98547a84",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the target image\n",
    "image.visualize(flag_colorbar = True, flag_axis = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c2e14",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Check the device of our target image\n",
    "print(\"Device: \", image.data.device) # Should be on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7234035a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Pre-Load Dataset to GPU\n",
    "datamodule.preload_dataset(device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d7aae7",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Device: \", datamodule.get_batch_IF_single(batch_idx=0).data.device)\n",
    "# Note this should be on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fdf0ef",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Step 2: Create the Lightning Object (that will manage the optimization procedure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da342c8",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Import our pre-implemented Lightning-Routine for SLM optimization\n",
    "from holotorch.Lightning_Modules.SLM_Lightning import SLM_Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afe6b4a",
   "metadata": {},
   "source": [
    "Finally create the Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b137013",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "slm_lightning = SLM_Lightning(\n",
    "    setup       = hologram_model,\n",
    "    datamodule  = datamodule,\n",
    "    lr_slm      = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7bd64e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<font size=\"4\">Step 2.2: PyTorch Lightning uses Trainer-objects to organize the training loop</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f1ee29",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning\n",
    "trainer = pytorch_lightning.Trainer(\n",
    "    enable_progress_bar = True, # for turning off progress bar\n",
    "    enable_model_summary= False, # for turning off weight summary.\n",
    "    max_epochs          = 200,\n",
    "    enable_checkpointing= False,\n",
    "    gpus                = 1,\n",
    "    profiler            = None,\n",
    "    logger              = None\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd6ec62",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Step 3: Run the optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebce03f",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    model       = slm_lightning,\n",
    "    datamodule  = slm_lightning.datamodule\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91700952",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "slm_lightning.visualize_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0481af76",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model_out = hologram_model()\n",
    "model_out.visualize(figsize=(10,15),\n",
    "                   title = \"Model Output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2b2ab7",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "slm_model.visualize_slm(figsize=(15,5),wavelengths \n",
    "                = hologram_model.source.wavelengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cdc686",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Etendue Expansion - Grace Kuo et al."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2485307b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center><img src=\"images/etendue_expansion.jpg\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e1d254",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "$$ \n",
    "I(x) = | FT [ H(u) \\cdot S(u) ]|^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\underset{S}{\\mathrm{argmin}}  || \\Big( | FT \\big( H \\cdot U(S) \\big) |^2 - T  \\Big) \\ast p ||^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "x: \\text{ Spatial Coordinates} , u: \\text{ Spatial Frequency Coordinates}\n",
    "$$\n",
    "$$\n",
    "FT: \\text{ Fourier Transform}\n",
    "$$\n",
    "$$\n",
    "H: \\text{Expander/Hologram to be optimized}\n",
    "$$\n",
    "$$\n",
    "U: \\text{ Upsampling Operator}\n",
    "$$\n",
    "$$\n",
    "T: \\text{Target image}\n",
    "$$\n",
    "$$\n",
    "S: \\text{ SLM-pattern to be optimized}\n",
    "$$\n",
    "$$\n",
    "p: \\text{ Perceptual filter kernel (for incoherent downsampling)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063fed7a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Let's create the etendue expansion setup in holotorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2984bc2a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import holotorch.Optical_Setups.Expansion_setup as Expansion_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f1ce5",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from holotorch.ComponentWrapper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce93557",
   "metadata": {},
   "source": [
    "Instead of directly creating our optical components, we will create \" parameter dictionaries\" which are more structured and easier to automate for parameter sweeps.\n",
    "<br>\n",
    "We will then use \"factory methods\" to create the actual optical components from their parameters dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301cef1d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model_args = PARAM_COMPONENT()\n",
    "model_args.num_pixel_x = 512\n",
    "model_args.num_pixel_y = 512\n",
    "model_args.spacing     = 8 * um\n",
    "model_args.eFac        = 4 # This means the field will be expanded to 4 * 512, 4 * 512\n",
    "model_args.wavelengths = 532 * nm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e335c538",
   "metadata": {},
   "source": [
    "<font size=\"4\">Create the source</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7353ca",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "source = PARAM_SOURCE()\n",
    "# ===========================================================\n",
    "source.source_type      = ENUM_SOURCE_TYPE.COHERENT\n",
    "source.height           = model_args.num_pixel_x\n",
    "source.width            = model_args.num_pixel_y\n",
    "source.grid_spacing     = model_args.spacing\n",
    "source.wavelengths      = model_args.wavelengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228369c8",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "mysource = create_source(source)\n",
    "print(mysource().data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3109a3",
   "metadata": {},
   "source": [
    "<font size=\"4\">Create the SLM</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef50ea3f",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "slm = PARAM_SLM()\n",
    "# ===========================================================\n",
    "slm.num_pixel_x         = model_args.num_pixel_x\n",
    "slm.num_pixel_y         = model_args.num_pixel_y\n",
    "slm.feature_size_slm    = model_args.spacing\n",
    "slm.SLM_TYPE            = ENUM_SLM_TYPE.phase_only\n",
    "slm.SLM_INIT            = ENUM_SLM_INIT.RANDOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d929c9",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "create_slm(slm) # The SLM output is be a 5D tensor \n",
    "# (since the SLM doesn't know about pupil sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb3cc7d",
   "metadata": {},
   "source": [
    "<font size=\"4\">Create the expander</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2293aaad",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "expander = PARAM_EXPANDER()\n",
    "# ===========================================================\n",
    "expander.num_pixel_x             = model_args.num_pixel_x * model_args.eFac\n",
    "expander.num_pixel_y             = model_args.num_pixel_y * model_args.eFac\n",
    "expander.spacing                 = source.grid_spacing / model_args.eFac\n",
    "expander.holo_type               = ENUM_HOLO_TYPE.phase_only\n",
    "expander.init_type               = ENUM_HOLO_INIT.RANDOM   \n",
    "expander.center_wavelength       = model_args.wavelengths \n",
    "# NOTE: Wavelength is needed for proper 2pi initialization of \"random expander phase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7562e6fb",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "create_expander(expander)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c617a1",
   "metadata": {},
   "source": [
    "<font size=\"4\">Create the propagator</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe16b9",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "propagator = PARAM_PROPAGATOR()\n",
    "# ===========================================================\n",
    "propagator.focal_length     = 35*mm\n",
    "propagator.prop_type        = ENUM_PROP_TYPE.FOURIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d550e41",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "create_propagator(propagator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37f4c85",
   "metadata": {},
   "source": [
    "Create a detector\n",
    "NOTE: The detector will automatically downsample the extended hologram back to the original resolution (acts as a perceptual filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b59e2c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "detector = PARAM_DETECTOR()\n",
    "# ===========================================================\n",
    "detector.num_pixel_x        = model_args.num_pixel_x\n",
    "detector.num_pixel_y        = model_args.num_pixel_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf79a97",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "create_detector(detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5620430",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Create the expansion setup from the component list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feee6636",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from holotorch.Optical_Setups.Expansion_setup import Expansion_setup\n",
    "expansion_cgh = Expansion_setup(\n",
    "    source      = source,\n",
    "    slm         = slm,\n",
    "    expander    = expander,\n",
    "    propagator  = propagator,\n",
    "    detector    = detector,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d176caa3",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model_out = expansion_cgh.forward()\n",
    "model_out.visualize(figsize=(10,10), title=\"Output with random initilization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a15616",
   "metadata": {},
   "source": [
    "#### Define the datamodule with the dataset we want to optimize for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983ca5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from holotorch.CGH_Datasets.Single_Image_Dataset import Single_Image_Dataset\n",
    "from holotorch.CGH_Datasets.HoloDataModule import HoloDataModule\n",
    "\n",
    "dataset = Single_Image_Dataset(\n",
    "    path = \"..//ExampleImages//tiger.png\",\n",
    "    num_pixel_x = model_args.num_pixel_x,\n",
    "    num_pixel_y = model_args.num_pixel_y,\n",
    "    grayscale = True,\n",
    ")\n",
    "\n",
    "datamodule = HoloDataModule(dataset = dataset)\n",
    "\n",
    "datamodule.get_batch_IF_single(0).visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b004bd78",
   "metadata": {},
   "source": [
    "#### Create the SLM_Lightning Module (this is actually the same we used before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4870259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from holotorch.Lightning_Modules.SLM_Lightning import SLM_Lightning\n",
    "import pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee12b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "lighting_cgh = SLM_Lightning(\n",
    "    setup       = expansion_cgh,\n",
    "    datamodule  = datamodule,\n",
    "    lr_slm      = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ae351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the trainer\n",
    "trainer = pytorch_lightning.Trainer(\n",
    "    enable_progress_bar = True, # for turning off progress bar\n",
    "    enable_model_summary= False, # for turning off weight summary.\n",
    "    max_epochs          = 100,\n",
    "    enable_checkpointing= False,\n",
    "    gpus                = 1,\n",
    "    profiler            = None,\n",
    "    logger              = None\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb45893d",
   "metadata": {},
   "source": [
    "#### Run the Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e049f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the hologram model\n",
    "trainer.fit(\n",
    "    model       = lighting_cgh,\n",
    "    datamodule  = lighting_cgh.datamodule\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9198dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "lighting_cgh.visualize_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e42a82",
   "metadata": {},
   "source": [
    "#### Let us visualize the optimization results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fdabf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_expansion_out : IntensityField = expansion_cgh.forward()\n",
    "target    = lighting_cgh.get_targets(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef20bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "plt.subplot(221)\n",
    "model_expansion_out.visualize(title=\"Expanded Hologram\")\n",
    "\n",
    "plt.subplot(222)\n",
    "model_expansion_out[...,100:200,100:200].visualize(\"Expanded Hologram\")\n",
    "\n",
    "plt.subplot(223)\n",
    "target.visualize(\"Target Image\")\n",
    "\n",
    "plt.subplot(224)\n",
    "target[...,100:200,100:200].visualize(\"Target Image\")\n",
    "\n",
    "plt.tight_layout() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e01c8d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Etendue Expansion ( Baek et al.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c1d19b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center><img src=\"images/NeuralEtendueExpansion.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5980e1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\underset{H, S_{ \\{ 1,...,K \\} }}{\\mathrm{argmin}} \\sum_{k=1}^{K} || \\Big( | FT \\big( H \\cdot U(S_k) \\big) |^2 - T_k  \\Big) \\ast p ||^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3858c6",
   "metadata": {},
   "source": [
    "$$\n",
    "FT: \\text{ Fourier Transform}\n",
    "$$\n",
    "$$\n",
    "H: \\text{ Expander/Hologram to be optimized}\n",
    "$$\n",
    "$$\n",
    "U: \\text{ Upsampling Operator}\n",
    "$$\n",
    "$$\n",
    "T_k: \\text{ k-th Target image}\n",
    "$$\n",
    "$$\n",
    "S_k: \\text{ k-th SLM-pattern to be optimized}\n",
    "$$\n",
    "$$\n",
    "p: \\text{ Perceptual filter kernel (for incoherent downsampling)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381bf9a0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Implementing Neural Etendue Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8673453",
   "metadata": {},
   "source": [
    "#### Now it's the first time that we'll use a dataset with more than one sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b3c9ce",
   "metadata": {},
   "source": [
    "First lets download the DIV2K dataset if we don't already have a copy locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c1ddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "div2k_extract_path      = pathlib.Path('../ExampleImages/div2k')\n",
    "div2k_zip_path          = div2k_extract_path / 'div2k.zip'\n",
    "div2k_image_folder      = div2k_extract_path / 'DIV2K_valid_HR'\n",
    "div2k_url               = 'http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip'\n",
    "\n",
    "div2k_extract_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475bc145",
   "metadata": {},
   "source": [
    "Check to see if div2k is already downloaded and extracted, otherwise download it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9ecd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if the image folder is populated with the correct number of files\n",
    "os.makedirs(div2k_extract_path, exist_ok=True)\n",
    "im_files = glob.glob( str( div2k_image_folder / '*.png' ) )\n",
    "\n",
    "if len(im_files) < 10:\n",
    "    \n",
    "    # download the div2k zipfile if it doesn't exist yet\n",
    "    if not div2k_zip_path.is_file():\n",
    "        response = urllib.request.urlretrieve(div2k_url, div2k_zip_path)\n",
    "    \n",
    "    # extract the zipfile into the correct directory\n",
    "    zipfile.ZipFile(div2k_zip_path).extractall(div2k_extract_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ef769a",
   "metadata": {},
   "source": [
    "Since Neural Etendue expansion easily fills up GPU-memory, we need to be careful with assigning the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc1910",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "param_dataset = PARAM_DATASET()\n",
    "param_dataset.batch_size        = 5 \n",
    "param_dataset.data_sz           = 15 # For this tutorial we keep the total number of samples small\n",
    "param_dataset.color_flag        = ENUM_SENSOR_TYPE.MONOCHROMATIC\n",
    "param_dataset.num_pixel_x       = model_args.num_pixel_x\n",
    "param_dataset.num_pixel_y       = model_args.num_pixel_y\n",
    "param_dataset.TYPE_dataloader   = ENUM_DATASET.DIV2K_Dataset\n",
    "param_dataset.data_folder       = div2k_image_folder\n",
    " \n",
    "datamodule = Factory_Dataset.create_data_module(param_dataset)\n",
    "print(datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa736a9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Pre-loading the dataset to GPU is important if you want to have fast speed. However, this will not work if the dataset doesn't fit into GPU-memory anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc235e8",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# This might take aa few seconds to process\n",
    "datamodule.preload_dataset( device= torch.cuda.current_device() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114c408a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "test_batch = datamodule.get_batch_IF(batch_idx=0)\n",
    "print(test_batch)\n",
    "test_batch.visualize_grid(figsize = (20,8), num_row = 1, num_col = 5, flag_colorbar = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f06a08d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "test_batch = datamodule.get_batch_IF(batch_idx=1)\n",
    "print(test_batch)\n",
    "test_batch.visualize_grid(figsize = (10,10), \n",
    "                          num_row = 1, num_col = 4,\n",
    "                          flag_colorbar = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1615757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = datamodule.get_batch_IF(batch_idx=2)\n",
    "print(test_batch)\n",
    "test_batch.visualize_grid(figsize = (10,10), \n",
    "                num_row = 2, num_col = 2, flag_colorbar = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489ff75",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Initialize the SLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d218e08c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "slm = PARAM_SLM()\n",
    "# ===========================================================\n",
    "slm.num_pixel_x         = model_args.num_pixel_x\n",
    "slm.num_pixel_y         = model_args.num_pixel_y\n",
    "slm.feature_size_slm    = model_args.spacing\n",
    "slm.SLM_TYPE            = ENUM_SLM_TYPE.phase_only\n",
    "slm.SLM_INIT            = ENUM_SLM_INIT.RANDOM\n",
    "slm.n_slm_batches       = datamodule.number_batches\n",
    "slm.data_sz             = len(datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685fef3f",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "NOTE: During optimization we need to save the \"state\" of each SLM. If the dataset size is small, we can do this on GPU. However, once the dataset becomes too large, we need to store the states of the SLM on disk.\n",
    "\n",
    "<br>\n",
    "Our SLM-class is able to take care of this automatically. You don't have to worry about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d3abe7",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "test_slm = create_slm(slm)\n",
    "print(test_slm) # The SLM should now carry 3 SLMs since the datamodule has 3 batches too\n",
    "print(datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45cd3fc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Let's assemble the expansion setup\n",
    "\n",
    "#### NOTE: We have defined an Expansion_Setup earlier and you only need to pass parameters to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af10153",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "neural_expansion_cgh = Expansion_setup(\n",
    "    source      = source,\n",
    "    slm         = slm,\n",
    "    expander    = expander,\n",
    "    propagator  = propagator,\n",
    "    detector    = detector,\n",
    "    ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d809b5e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "neural_expansion_cgh.print_param_nice()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe32a0e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's initialize the Neural_Expander_Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe96d3e",
   "metadata": {},
   "source": [
    "NOTE: For Neural etendue expansion we iterate between optimizing the expander and optimizing the SLM-patterns for each image in the dataset.\n",
    "<br>\n",
    "We need a initialize a lot of ADAM-optimizers and keep track of many different parameters. \n",
    "<br>\n",
    "We have implemented all of this in *Neural_Expander_Lightning* for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60175ff1",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from holotorch.Lightning_Modules.Neural_Expander_Lightning import Neural_Expander_Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af39795e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "neural_expander_lighnting = Neural_Expander_Lightning(\n",
    "    datamodule  = datamodule,\n",
    "    setup       = neural_expansion_cgh,\n",
    "    lr_expander = 0.25 * 1e-2,\n",
    "    lr_slm      = 0.25,\n",
    "    num_preinitialize = 25\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26788801",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Create the trainer\n",
    "trainer = pytorch_lightning.Trainer(\n",
    "    enable_progress_bar = True, # for turning off progress bar\n",
    "    enable_model_summary= False, # for turning off weight summary.\n",
    "    max_epochs          = 100,\n",
    "    enable_checkpointing= False,\n",
    "    gpus                = 1,\n",
    "    profiler            = None,\n",
    "    logger              = None\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d41ee4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Run the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b504c0a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# train the hologram model\n",
    "trainer.fit(\n",
    "    model       = neural_expander_lighnting,\n",
    "    datamodule  = neural_expander_lighnting.datamodule\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069c4faa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "neural_expander_lighnting.visualize_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7604e9",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "neural_expansion_cgh.forward(batch_idx=1).visualize_grid(max_images=5,\n",
    "                                              num_row = 1, num_col = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5448657a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "neural_expansion_cgh.forward(batch_idx=2).visualize_grid(max_images=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f1f3bf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What about saving and loading our models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579c3a20",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "save_folder = pathlib.Path(\".//results//neural_expansion\")\n",
    "# Holotorch uses pathlib a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d3a8a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "neural_expander_filename = save_folder / \"neural_expansion.ht\"\n",
    "neural_expansion_cgh.save_model(neural_expander_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52bff0e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We also need to save the different SLM batches indiviually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3907c7e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "slm_folder = save_folder / \"optimized_slms\"\n",
    "print(slm_folder.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347406bb",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "neural_expansion_cgh.slm.save_all_slms_into_folder(slm_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82abe346",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "filenames = next(walk(slm_folder), (None, None, []))[2]  # [] if no file\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09190bd9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How can we load our model again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b90883",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "optimized_neural_etendue_setup = Base_Setup.load_pickle_object(neural_expander_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c34312",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(slm_folder)\n",
    "optimized_neural_etendue_setup.slm.load_all_slms_from_folder(slm_folder) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386953d8",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "neural_expansion_output = optimized_neural_etendue_setup.forward(batch_idx=1)\n",
    "neural_expansion_output.visualize_grid(max_images=5, num_row = 1, num_col = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d4bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_expansion_output = optimized_neural_etendue_setup.forward(batch_idx=0)\n",
    "neural_expansion_output.visualize_grid(max_images=5, num_row = 1, num_col = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89332f28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's compare against conventional \"etendue expansion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee57e6e8",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# FIRST: Let's move the place where we store the \"temporary\" SLM-states for Neural Etendue Expansion\n",
    "print(\"Folder before move:\", optimized_neural_etendue_setup.slm.tmp_dir)\n",
    "optimized_neural_etendue_setup.slm.move_tmp_save_folder(slm_id=\"neural_expansion\")\n",
    "print(\"Folder after move:\",optimized_neural_etendue_setup.slm.tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae38f6a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    " # Specify where we save the SLM states to avoid conflict\n",
    "slm.slm_id = \"simple_expansion\"\n",
    "expansion_cgh = Expansion_setup(\n",
    "    source      = source,\n",
    "    slm         = slm,\n",
    "    expander    = expander,\n",
    "    propagator  = propagator,\n",
    "    detector    = detector,\n",
    "    ).cuda()\n",
    "\n",
    "print(\"New Save Folder\", expansion_cgh.slm.tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df43d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to make sure we're still using the correct datamodule\n",
    "print(datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41aa943",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "lighting_cgh = SLM_Lightning(\n",
    "    setup       = expansion_cgh,\n",
    "    datamodule  = datamodule,\n",
    "    lr_slm      = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c33db",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Create the trainer\n",
    "trainer = pytorch_lightning.Trainer(\n",
    "    enable_progress_bar = True, # for turning off progress bar\n",
    "    enable_model_summary= False, # for turning off weight summary.\n",
    "    max_epochs          = 50,\n",
    "    enable_checkpointing= False,\n",
    "    gpus                = 1,\n",
    "    profiler            = None,\n",
    "    logger              = None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e3da3b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# train the hologram model\n",
    "trainer.fit(\n",
    "    model       = lighting_cgh,\n",
    "    datamodule  = lighting_cgh.datamodule\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f4430",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lighting_cgh.visualize_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054c1f5a",
   "metadata": {},
   "source": [
    "Visualize the output of neural and conventional etendue expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ff85c3",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "batch_idx_to_visualize = 1\n",
    "\n",
    "# Get the ground truth\n",
    "ground_truth = datamodule.get_batch_IF(batch_idx=batch_idx_to_visualize)\n",
    "\n",
    "# Get the normal etendue expansion output\n",
    "normal_expansion_output = expansion_cgh.forward(batch_idx=batch_idx_to_visualize)\n",
    "normal_expansion_output.visualize_grid(max_images=5, num_row = 1, num_col = 4, vmin = 0)\n",
    "\n",
    "# Get the neural etendue expansion output\n",
    "neural_expansion_output = optimized_neural_etendue_setup.forward(batch_idx=batch_idx_to_visualize)\n",
    "neural_expansion_output.visualize_grid(max_images=5, num_row = 1, num_col = 4, vmin = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0497de6a",
   "metadata": {},
   "source": [
    "Let's look at single out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac87f2",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "img_idx = 0\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(131)\n",
    "ground_truth[0].visualize(title='Ground Truth', flag_colorbar = False)\n",
    "plt.subplot(132)\n",
    "normal_expansion_output[img_idx].visualize(title='Simple Expansion', flag_colorbar = False, vmin = 0)\n",
    "plt.subplot(133)\n",
    "neural_expansion_output[img_idx].visualize(title='Neural Expansion', flag_colorbar = False, vmin = 0)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de8adf",
   "metadata": {},
   "source": [
    "Let's zoom into to see the difference in noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8039d9df",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "img_idx = 4\n",
    "x0 = 50\n",
    "x1 = 150\n",
    "y0 = 200\n",
    "y1 = 300\n",
    "plt.subplot(311)\n",
    "ground_truth[img_idx,...,x0:x1,y0:y1].visualize(title='Ground Truth', flag_colorbar = False)\n",
    "plt.subplot(312)\n",
    "normal_expansion_output[img_idx,...,x0:x1,y0:y1].visualize(title='Simple Expansion', flag_colorbar = False)\n",
    "plt.subplot(313)\n",
    "neural_expansion_output[img_idx,...,x0:x1,y0:y1].visualize(title='Neural Expansion', flag_colorbar = False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1162e11",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Holotorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2d57ad",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "A coherent imaging/display framework in progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f88def",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Contact:\n",
    "<br>\n",
    "Florian Schiffers: florian.schiffers@u.northwestern.edu\n",
    "<br>\n",
    "Oliver Cossairt: oliver.cossairt@northwestern.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b3d3ea",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "GitHub Link: https://github.com/facebookresearch/holotorch"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.8.13 ('holotorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "rise": {
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "simple",
   "transition": "linear"
  },
  "vscode": {
   "interpreter": {
    "hash": "86275e26590537324feaefb9e7c0fc77796461a8030f18999e15954644917588"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
